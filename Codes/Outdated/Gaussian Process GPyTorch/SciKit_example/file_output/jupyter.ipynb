{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.use(\"PDF\")\n",
    "\n",
    "np.random.seed(rnd.randint(0, 1000000)) # makes it possible for .permutation() to be randomized every single run of the code\n",
    "\n",
    "\"\"\" Emrecan Serin 11/10/22 -\n",
    "Comment 1: I have added a random integer number generator into np.random.seed() to make sure LF and HF points changed everytime the code is run.\n",
    "\n",
    "Comment 2: I have realised that \"L1mean\" was a column array and \".hstack\" function on line 63 was trying to stack a row (X_hf) with a column (L1mean). \n",
    "So I added .reshape(-1,1) on line 58 to turn \"L1mean\" into a row array to fix the array dimension error.\n",
    "\n",
    "Comment 3: I have had problems on lines 83, 91 and 101 with \".fill_between\" function from matplotlib, I was getting \"too many indices for array\" error,\n",
    "probably because of how I played with the code to make it work or some other reason. As a solution, I have tried multiple things that came to my mind for \n",
    "hours but could not fix it. I commented them out in the end and the plot seems to be working fine.\n",
    "\n",
    "Comment 4: I had a familiar array dimension problem with line 94 so I used .reshape(-1,1) again to fix it.\n",
    "\"\"\"\n",
    "start_timer = time.time()\n",
    "def hf(x): # defines the hf and lf sine functions\n",
    "    return 1.8*np.sin(8.0*np.pi*x)*2*x  # the accurately simulated sin model for HF data\n",
    "\n",
    "\n",
    "def lf(x):\n",
    "    return np.sin(8.0*np.pi*x)*x # the inaccurately simulated sin model for LF data\n",
    "\n",
    "\n",
    "# X = np.linspace(-np.pi, np.pi, 1000)[:, np.newaxis]\n",
    "X = np.linspace(0, 1, 1000)[:,np.newaxis] # Increases the dimension of the array from 1D to 2D to 3D... Also turns it into a row vector if it's from 1D to 2D\n",
    "\n",
    "Nhf=10 # Using the linspace with pi, a lot more points were needed to get an accurate model.\n",
    "Nlf=50\n",
    "\n",
    "#sample LF and hF model randomly\n",
    "X_lf = np.random.permutation(X)[0:Nlf] # basically randomly aranges the 50 different values in X array, from 0 to 50 [0:Nlf(50)]  \"print(len(X_lf)) = 50\"\n",
    "X_hf = np.random.permutation(X_lf)[0:Nhf]\n",
    "\n",
    "print(X_hf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emjan\\AppData\\Local\\VisualStudioCode\\Dissertation_Venv\\dis_env\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:616: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_hf = GaussianProcessRegressor(kernel=RBF(), n_restarts_optimizer=200).fit(X_hf,hf(X_hf)) # Gaussian Regressor by sklearn\n",
    "gpr_lf = GaussianProcessRegressor(kernel=RBF(), n_restarts_optimizer=200).fit(X_lf,lf(X_lf)) #.fit learns the correlation betwen the two values\n",
    "\n",
    "pred_hf_mean, pred_hf_std = gpr_hf.predict(X, return_std=True)\n",
    "pred_lf_mean, pred_lf_std = gpr_lf.predict(X, return_std=True)\n",
    "pred_hf_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# MF start point\n",
    "L1mean = gpr_lf.predict(X_hf)\n",
    "\n",
    "L1mean = L1mean.reshape(-1,1)\n",
    "\n",
    "L2_train = np.hstack((X_hf, L1mean))\n",
    "\n",
    "print(L2_train.shape)\n",
    "\n",
    "gpr_mf_l2 = GaussianProcessRegressor(kernel=RBF()*RBF()+RBF(),n_restarts_optimizer=200).fit(L2_train,hf(X_hf))\n",
    "\n",
    "print(pred_lf_mean.shape)\n",
    "\n",
    "L2_test = np.hstack((X, pred_lf_mean))\n",
    "\n",
    "pred_mf_mean, pred_mf_std = gpr_mf_l2.predict(L2_test, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 0.0923463503519694 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Plotting -- \n",
    "\n",
    "fig, axs = plt.subplots(4)\n",
    "axs[0].plot(X,hf(X),label=\"High Fidelity / Exact\") # main result line we want to match with\n",
    "axs[0].plot(X_lf, lf(X_lf),'bo', label=\"Low fidelity samples\") # low fidelity dots\n",
    "axs[0].plot(X_hf, hf(X_hf),'ro', label=\"High fidelity samples\") # high fidelity dots\n",
    "axs[0].legend(bbox_to_anchor=(0.9, 1), loc='upper left', fontsize='x-small')\n",
    "\n",
    "\n",
    "\n",
    "axs[1].plot(X,hf(X),label=\"High Fidelity / Exact\")\n",
    "axs[1].plot(X, pred_hf_mean, 'k', lw=3, label=\"GP mean (trained on red dots)\")\n",
    "axs[1].plot(X_hf, hf(X_hf),'ro', label=\"High fidelity samples\")\n",
    "# axs[1].fill_between(X[:,0], pred_hf_mean[:,0]-pred_hf_std, pred_hf_mean[:,0]+pred_hf_std,alpha=0.2, color='k', label=\"+/- 1 std\")\n",
    "axs[1].legend(bbox_to_anchor=(0.9, 1), loc='upper left', fontsize='x-small')\n",
    "\n",
    "\n",
    "\n",
    "axs[2].plot(X,hf(X),label=\"High Fidelity / Exact\")\n",
    "axs[2].plot(X, pred_lf_mean, 'k', lw=3, label=\"GP mean (trained on blue dots)\")\n",
    "axs[2].plot(X_lf, lf(X_lf),'bo', label=\"Low fidelity samples\")\n",
    "# axs[2].fill_between(X[:,0], pred_lf_mean[:,0]-2*pred_lf_std, pred_lf_mean[:,0]+2*pred_lf_std,alpha=0.2, color='k', label=\"+/- 2 std\")\n",
    "axs[2].legend(bbox_to_anchor=(0.9, 1), loc='upper left', fontsize='x-small')\n",
    "\n",
    "\n",
    "\n",
    "axs[3].plot(X,hf(X),label=\"High Fidelity / Exact\")\n",
    "axs[3].plot(X, pred_mf_mean, 'k', lw=3, label=\"Deep GP mean (trained on all dots)\")\n",
    "# axs[3].fill_between(X[:,0], pred_mf_mean[:,0]-2*pred_mf_std, pred_mf_mean[:,0]+2*pred_mf_std,alpha=0.2, color='k', label=\"+/- 2 std\")\n",
    "axs[3].legend(bbox_to_anchor=(0.9, 1), loc='upper left', fontsize='x-small')\n",
    "\n",
    "fig.text(0.5, 0.03, '$x$', ha='center')\n",
    "fig.text(0.03, 0.5, '$y=f(x)$', va='center', rotation='vertical')\n",
    "\n",
    "\n",
    "plt.savefig(\"plot.pdf\")\n",
    "\n",
    "print(f\"Finished in {(time.time() - start_timer)/60} minutes.\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53a9d46bace0d87d5d8b47eb975286de82fb882fc38f144f4a3850996fb362a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
