{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFRegress:\n",
    "    def __init__(self, x_lf, lf, x_hf, hf,\n",
    "                 embedding_theory=True,\n",
    "                 gradient=False):\n",
    "        import numpy as np\n",
    "\n",
    "        self.x_lf = x_lf\n",
    "        self.lf = lf\n",
    "        self.x_hf = x_hf\n",
    "        self.hf = hf\n",
    "        self.embedding_theory = embedding_theory\n",
    "        self.gradient = gradient\n",
    "        xmin = min(min(self.x_lf), min(self.x_hf))\n",
    "        xmax = max(max(self.x_lf), max(self.x_hf))\n",
    "        self.x = np.linspace(xmin, xmax, 1001)[:, np.newaxis]\n",
    "\n",
    "    def prep(self):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        import numpy as np\n",
    "\n",
    "        self.x_lf = self.x_lf.reshape(-1, 1)\n",
    "        self.x_hf = self.x_hf.reshape(-1, 1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(self.x)\n",
    "        self.x_lf = scaler.transform(self.x_lf)\n",
    "        self.x_hf = scaler.transform(self.x_hf)\n",
    "        self.x = scaler.transform(self.x)\n",
    "        if len(np.shape(self.lf)) == 1:\n",
    "            self.lf = self.lf.T\n",
    "            self.hf = self.hf.T\n",
    "            self.lf = self.lf.reshape(-1, 1)\n",
    "            self.hf = self.hf.reshape(-1, 1)\n",
    "        datascaler = MinMaxScaler()\n",
    "        datascaler.fit(self.lf)\n",
    "        self.lf = datascaler.transform(self.lf)\n",
    "        self.hf = datascaler.transform(self.hf)\n",
    "\n",
    "        return scaler, datascaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfgp(self, kernel_lf, kernel_hf):\n",
    "    import numpy as np\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "    if len(np.shape(self.lf)) == 1:\n",
    "        single = True\n",
    "        print('single')\n",
    "    else:\n",
    "        single = False\n",
    "\n",
    "    scaler, datascaler = self.prep()\n",
    "\n",
    "    gpr_lf = GaussianProcessRegressor(kernel=kernel_lf,\n",
    "                                        n_restarts_optimizer=200,\n",
    "                                        normalize_y=True).fit(self.x_lf, self.lf)\n",
    "    gpr_hf = GaussianProcessRegressor(kernel=kernel_hf,\n",
    "                                        n_restarts_optimizer=200,\n",
    "                                        normalize_y=True).fit(self.x_hf, self.hf)\n",
    "\n",
    "    l1mean = gpr_lf.predict(self.x_hf)\n",
    "\n",
    "    if self.embedding_theory:\n",
    "        l1mean_shift1 = gpr_lf.predict(self.x_hf+0.02)\n",
    "        l1mean_shift2 = gpr_lf.predict(self.x_hf+0.04)\n",
    "        l2_train = np.hstack((self.x_hf, l1mean, l1mean_shift1, l1mean_shift2))\n",
    "    else:\n",
    "        l2_train = np.hstack((self.x_hf, l1mean))\n",
    "\n",
    "    k_mf = kernel_hf * kernel_hf + kernel_hf\n",
    "    gpr_mf_l2 = GaussianProcessRegressor(kernel=k_mf,\n",
    "                                            n_restarts_optimizer=200,\n",
    "                                            normalize_y=True).fit(l2_train, self.hf)\n",
    "\n",
    "    pred_hf_mean = gpr_hf.predict(self.x, return_std=single)\n",
    "    pred_lf_mean = gpr_lf.predict(self.x, return_std=single)\n",
    "\n",
    "    if single:\n",
    "        pred_lf_std = pred_lf_mean[1]\n",
    "        pred_lf_mean = pred_lf_mean[0]\n",
    "        pred_hf_std = pred_hf_mean[1]\n",
    "        pred_hf_mean = pred_hf_mean[0]\n",
    "    else:\n",
    "        pred_lf_std = np.zeros(len(pred_lf_mean))\n",
    "        pred_hf_std = np.zeros(len(pred_hf_mean))\n",
    "\n",
    "    if self.embedding_theory:\n",
    "        pred_lf_mean_shift1 = gpr_lf.predict(self.x + 0.02, return_std=False)\n",
    "        pred_lf_mean_shift2 = gpr_lf.predict(self.x + 0.04, return_std=False)\n",
    "        l2_test = np.hstack((self.x, pred_lf_mean, pred_lf_mean_shift1, pred_lf_mean_shift2))\n",
    "    else:\n",
    "        l2_test = np.hstack((self.x, pred_lf_mean))\n",
    "\n",
    "    pred_mf_mean = gpr_mf_l2.predict(l2_test, return_std=single)\n",
    "\n",
    "    if single:\n",
    "        pred_mf_std = pred_mf_mean[1]\n",
    "        pred_mf_mean = pred_mf_mean[0]\n",
    "\n",
    "    else:\n",
    "        pred_mf_std = np.zeros(len(pred_mf_mean))\n",
    "\n",
    "    self.x = scaler.inverse_transform(self.x)\n",
    "    pred_lf_mean = datascaler.inverse_transform(pred_lf_mean)\n",
    "    pred_hf_mean = datascaler.inverse_transform(pred_hf_mean)\n",
    "    pred_mf_mean = datascaler.inverse_transform(pred_mf_mean)\n",
    "    if single:\n",
    "        pred_lf_std *= datascaler.data_range_\n",
    "        pred_hf_std *= datascaler.data_range_\n",
    "        pred_mf_std *= datascaler.data_range_\n",
    "\n",
    "    return self.x, pred_lf_mean, pred_lf_std, pred_hf_mean, pred_hf_std, pred_mf_mean, pred_mf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfmlp(self,\n",
    "            hidden_layers1=(20, 50, 50, 50, 20),\n",
    "            hidden_layers2=(20, 20, 20, 20),\n",
    "            solver='lbfgs',\n",
    "            activation='tanh'\n",
    "            ):\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    from sklearn.exceptions import DataConversionWarning\n",
    "    warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "    if len(np.shape(self.lf)) == 1:\n",
    "        single = True\n",
    "    else:\n",
    "        single = False\n",
    "        \n",
    "    scaler, datascaler = self.prep()\n",
    "\n",
    "    mlpr_lf = MLPRegressor(activation=activation,\n",
    "                            hidden_layer_sizes=hidden_layers1,\n",
    "                            solver=solver,\n",
    "                            random_state=1,\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=5000).fit(self.x_lf, self.lf)\n",
    "    mlpr_hf = MLPRegressor(activation=activation,\n",
    "                            hidden_layer_sizes=hidden_layers2,\n",
    "                            solver=solver,\n",
    "                            random_state=1,\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=5000).fit(self.x_hf, self.hf)\n",
    "\n",
    "    l1mean = mlpr_lf.predict(self.x_hf)\n",
    "    if single:\n",
    "        l1mean = l1mean.reshape(-1, 1)\n",
    "        \n",
    "    l2_train = np.hstack((self.x_hf, l1mean))\n",
    "    \n",
    "    if self.embedding_theory:\n",
    "        l1mean_shift1 = mlpr_lf.predict(self.x_hf + 0.02)\n",
    "        l1mean_shift2 = mlpr_lf.predict(self.x_hf + 0.04)\n",
    "        if single:\n",
    "            l1mean_shift1 = l1mean_shift1.reshape(-1, 1)\n",
    "            l1mean_shift2 = l1mean_shift2.reshape(-1, 1)\n",
    "        l2_train = np.concatenate((l2_train, l1mean_shift1, l1mean_shift2), axis=1)\n",
    "        \n",
    "    if self.gradient:\n",
    "        l1mean_gradient = np.gradient(l1mean, axis=1)\n",
    "        if single:\n",
    "            l1mean_gradient = l1mean_gradient.reshape(-1, 1)\n",
    "        l2_train = np.concatenate((l2_train, l1mean_gradient), axis=1)\n",
    "                    \n",
    "    mlpr_mf_nlin = MLPRegressor(activation=activation,\n",
    "                                hidden_layer_sizes=hidden_layers2,\n",
    "                                solver=solver,\n",
    "                                random_state=1,\n",
    "                                alpha=0.0001,\n",
    "                                max_iter=5000).fit(l2_train, self.hf)\n",
    "\n",
    "    pred_hf_mean = mlpr_hf.predict(self.x)\n",
    "    pred_lf_mean = mlpr_lf.predict(self.x)\n",
    "    if single:\n",
    "        pred_hf_mean = pred_hf_mean.reshape(-1, 1)\n",
    "        pred_lf_mean = pred_lf_mean.reshape(-1, 1)\n",
    "\n",
    "    l2_test = np.hstack((self.x, pred_lf_mean))\n",
    "\n",
    "    if self.embedding_theory:\n",
    "        pred_lf_mean_shift1 = mlpr_lf.predict(self.x + 0.02)\n",
    "        pred_lf_mean_shift2 = mlpr_lf.predict(self.x + 0.04)\n",
    "        if single:\n",
    "            pred_lf_mean_shift1 = pred_lf_mean_shift1.reshape(-1, 1)\n",
    "            pred_lf_mean_shift2 = pred_lf_mean_shift2.reshape(-1, 1)\n",
    "        l2_test = np.concatenate((l2_test, pred_lf_mean_shift1, pred_lf_mean_shift2), axis=1)\n",
    "        \n",
    "    if self.gradient:\n",
    "        pred_lf_mean_gradient = np.gradient(pred_lf_mean, axis=1)\n",
    "        if single:\n",
    "            pred_lf_mean_gradient = pred_lf_mean_gradient.reshape(-1, 1)\n",
    "        l2_test = np.concatenate((l2_test, pred_lf_mean_gradient), axis=1)\n",
    "\n",
    "    pred_mf_mean = mlpr_mf_nlin.predict(l2_test)\n",
    "    if single:\n",
    "        pred_mf_mean = pred_mf_mean.reshape(-1, 1)\n",
    "\n",
    "    pred_lf_std = np.zeros(len(pred_lf_mean))\n",
    "    pred_hf_std = np.zeros(len(pred_hf_mean))\n",
    "    pred_mf_std = np.zeros(len(pred_mf_mean))\n",
    "\n",
    "    self.x = scaler.inverse_transform(self.x)\n",
    "    pred_lf_mean = datascaler.inverse_transform(pred_lf_mean)\n",
    "    pred_hf_mean = datascaler.inverse_transform(pred_hf_mean)\n",
    "    pred_mf_mean = datascaler.inverse_transform(pred_mf_mean)\n",
    "\n",
    "    return self.x, pred_lf_mean, pred_lf_std, pred_hf_mean, pred_hf_std, pred_mf_mean, pred_mf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mfmlp2(self, lf2, hf2, old_result):\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.ensemble import StackingRegressor\n",
    "    import numpy as np\n",
    "    \n",
    "    scaler, datascaler = self.prep()\n",
    "\n",
    "    lf2 = lf2.T\n",
    "    hf2 = hf2.T\n",
    "    old_result = old_result.T\n",
    "    lf2 = lf2.reshape(-1, 1)\n",
    "    hf2 = hf2.reshape(-1, 1)\n",
    "    old_result = old_result.reshape(-1, 1)\n",
    "    lf2 = datascaler.transform(lf2)\n",
    "    hf2 = datascaler.transform(hf2)\n",
    "    old_result = datascaler.transform(old_result)\n",
    "\n",
    "    solver = 'lbfgs'\n",
    "    activation = 'tanh'\n",
    "    # activation = 'relu'\n",
    "    hidden_layers1 = (20, 50, 50, 50, 20)\n",
    "    hidden_layers2 = (20, 20, 20, 20)\n",
    "\n",
    "    mlpr_lf = MLPRegressor(activation=activation,\n",
    "                            hidden_layer_sizes=hidden_layers1,\n",
    "                            solver=solver,\n",
    "                            random_state=1,\n",
    "                            max_iter=1000).fit(np.hstack((self.x_lf, lf2)), self.lf)\n",
    "    mlpr_hf = MLPRegressor(activation=activation,\n",
    "                            hidden_layer_sizes=hidden_layers2,\n",
    "                            solver=solver,\n",
    "                            random_state=1,\n",
    "                            max_iter=1000).fit(self.x_hf, self.hf)\n",
    "\n",
    "    l1mean = mlpr_lf.predict(np.hstack((self.x_hf, hf2))).reshape(-1, 1)\n",
    "    l1mean_shift1 = mlpr_lf.predict(np.hstack((self.x_hf+0.02, hf2))).reshape(-1, 1)\n",
    "    l1mean_shift2 = mlpr_lf.predict(np.hstack((self.x_hf+0.04, hf2))).reshape(-1, 1)\n",
    "    l2_train = np.hstack((self.x_hf, hf2, l1mean, l1mean_shift1, l1mean_shift2))\n",
    "    # l2_train = np.hstack((x_hf, l1mean))\n",
    "\n",
    "    mlpr_mf_nlin = MLPRegressor(activation=activation,\n",
    "                                hidden_layer_sizes=hidden_layers2,\n",
    "                                solver=solver,\n",
    "                                random_state=1,\n",
    "                                # alpha=0.0001,\n",
    "                                max_iter=1000).fit(l2_train, self.hf)\n",
    "\n",
    "    pred_hf_mean = mlpr_hf.predict(self.x).reshape(-1, 1)\n",
    "    pred_lf_mean = mlpr_lf.predict(np.hstack((self.x, old_result))).reshape(-1, 1)\n",
    "    pred_lf_mean_shift1 = mlpr_lf.predict(np.hstack((self.x + 0.02, old_result))).reshape(-1, 1)\n",
    "    pred_lf_mean_shift2 = mlpr_lf.predict(np.hstack((self.x + 0.04, old_result))).reshape(-1, 1)\n",
    "\n",
    "    l2_test = np.hstack((self.x, old_result, pred_lf_mean, pred_lf_mean_shift1, pred_lf_mean_shift2))\n",
    "    # l2_test = np.hstack((x, pred_lf_mean))\n",
    "    pred_mf_mean = mlpr_mf_nlin.predict(l2_test)\n",
    "    pred_mf_mean = pred_mf_mean.reshape(-1, 1)\n",
    "\n",
    "    pred_lf_std = np.zeros(len(pred_lf_mean))\n",
    "    pred_hf_std = np.zeros(len(pred_hf_mean))\n",
    "    pred_mf_std = np.zeros(len(pred_mf_mean))\n",
    "\n",
    "    self.x = scaler.inverse_transform(self.x)\n",
    "    pred_lf_mean = datascaler.inverse_transform(pred_lf_mean)\n",
    "    pred_hf_mean = datascaler.inverse_transform(pred_hf_mean)\n",
    "    pred_mf_mean = datascaler.inverse_transform(pred_mf_mean)\n",
    "\n",
    "    return self.x, pred_lf_mean, pred_lf_std, pred_hf_mean, pred_hf_std, pred_mf_mean, pred_mf_std\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53a9d46bace0d87d5d8b47eb975286de82fb882fc38f144f4a3850996fb362a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
